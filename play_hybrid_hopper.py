#!/usr/bin/env python3
"""
Play Hybrid Hopper - Headlessæ¨¡å¼æµ‹è¯•
å‚è€ƒHopper_rl_t-master/hopper_gym/scripts/play.py
"""

import sys
import os

# å¿…é¡»å…ˆimport isaacgym
sys.path.append('/home/abc/walk_these_ways_learning/isaacgym/python')
sys.path.append('/home/abc/walk_these_ways_learning/walk-these-ways')

from isaacgym import gymutil, gymapi

# ç°åœ¨å¯ä»¥importå…¶ä»–æ¨¡å—
from go1_gym.envs.base.legged_robot_config import Cfg
from go1_gym.envs.hybrid_hopper.hybrid_hopper_config import config_hybrid_hopper
from go1_gym.envs.hybrid_hopper.velocity_tracking import VelocityTrackingEasyEnv

import torch
import numpy as np

def play_hybrid_hopper(headless=True, num_steps=1000):
    """
    Play Hybrid Hopperç¯å¢ƒ
    
    Args:
        headless: æ˜¯å¦headlessæ¨¡å¼ï¼ˆä¸æ˜¾ç¤ºGUIï¼‰
        num_steps: è¿è¡Œæ­¥æ•°
    """
    print("\n" + "="*70)
    print("ğŸ® Play Hybrid Hopper (Headless Mode)")
    print("="*70)
    
    # é…ç½®ç¯å¢ƒ
    config_hybrid_hopper(Cfg)
    
    # ç®€åŒ–é…ç½®ç”¨äºplay
    Cfg.env.num_envs = 4  # å°‘é‡ç¯å¢ƒ
    Cfg.terrain.mesh_type = 'plane'  # å¹³é¢åœ°å½¢
    Cfg.domain_rand.randomize_friction = False
    Cfg.domain_rand.randomize_base_mass = False
    Cfg.domain_rand.push_robots = False
    Cfg.commands.resampling_time = 100.0
    
    # è®¾ç½®åˆå§‹å‘½ä»¤ï¼ˆè®©æœºå™¨äººå°è¯•å‰è¿›ï¼‰
    Cfg.commands.lin_vel_x = [0.3, 0.3]  # 0.3 m/så‰è¿›
    Cfg.commands.lin_vel_y = [0.0, 0.0]
    Cfg.commands.ang_vel_yaw = [0.0, 0.0]
    
    print(f"\nğŸ“Š é…ç½®ä¿¡æ¯:")
    print(f"  Headless: {headless}")
    print(f"  ç¯å¢ƒæ•°é‡: {Cfg.env.num_envs}")
    print(f"  DOF: {Cfg.env.num_actions}")
    print(f"  è§‚å¯Ÿç»´åº¦: {Cfg.env.num_observations}")
    print(f"  è¿è¡Œæ­¥æ•°: {num_steps}")
    
    # åˆ›å»ºsim_params
    sim_params = gymapi.SimParams()
    gymutil.parse_sim_config(vars(Cfg.sim), sim_params)
    
    print(f"\nâš™ï¸ Simå‚æ•°:")
    print(f"  use_gpu_pipeline: {sim_params.use_gpu_pipeline}")
    print(f"  dt: {sim_params.dt}")
    print(f"  substeps: {sim_params.substeps}")
    
    # åˆ›å»ºç¯å¢ƒ
    print(f"\nğŸ¤– åˆ›å»ºç¯å¢ƒï¼ˆ{'headless' if headless else 'GUI'}æ¨¡å¼ï¼‰...")
    try:
        env = VelocityTrackingEasyEnv(
            sim_device='cuda:0',
            headless=headless,
            cfg=Cfg
        )
        print("âœ… ç¯å¢ƒåˆ›å»ºæˆåŠŸï¼")
    except Exception as e:
        print(f"âŒ ç¯å¢ƒåˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # ç¯å¢ƒä¿¡æ¯
    print(f"\nğŸ“‹ ç¯å¢ƒä¿¡æ¯:")
    print(f"  è‡ªç”±åº¦æ•°é‡: {env.num_dof}")
    print(f"  åˆšä½“æ•°é‡: {env.num_bodies}")
    print(f"  Foot indices: {env.feet_indices}")
    
    # DOF names
    if hasattr(env, 'dof_names'):
        print(f"\nğŸ“‹ DOFåˆ—è¡¨:")
        for i, name in enumerate(env.dof_names):
            print(f"  [{i}] {name}")
    
    # é‡ç½®ç¯å¢ƒ
    print(f"\nğŸ”„ é‡ç½®ç¯å¢ƒ...")
    obs = env.reset()
    print(f"âœ… ç¯å¢ƒå·²é‡ç½®")
    print(f"   Observation shape: {obs.shape}")
    
    # å‡†å¤‡ç»Ÿè®¡æ•°æ®
    rewards_history = []
    heights_history = []
    velocities_history = []
    
    print("\n" + "="*70)
    print("âš¡ å¼€å§‹è¿è¡Œä»¿çœŸ...")
    print("="*70)
    
    # ä¸»å¾ªç¯
    for step in range(num_steps):
        # ç”ŸæˆéšæœºåŠ¨ä½œï¼ˆæˆ–ä½¿ç”¨ç­–ç•¥ï¼‰
        # actions shape: (num_envs, num_actions)
        if step < 100:
            # å‰100æ­¥ï¼šä¿æŒé™æ­¢
            actions = torch.zeros(env.num_envs, env.num_actions, device=env.device)
        else:
            # ä¹‹åï¼šéšæœºå°åŠ¨ä½œæµ‹è¯•
            actions = torch.randn(env.num_envs, env.num_actions, device=env.device) * 0.1
            
            # æ—‹ç¿¼å§‹ç»ˆç»™ä¸€äº›æ¨åŠ›ï¼ˆå¸®åŠ©æ‚¬åœï¼‰
            if env.num_actions >= 7:  # æœ‰æ—‹ç¿¼
                actions[:, 3:7] = 0.2  # å°æ¨åŠ›
        
        # æ‰§è¡ŒåŠ¨ä½œ
        obs, _, rewards, dones, infos = env.step(actions)
        
        # æ”¶é›†ç»Ÿè®¡æ•°æ®
        rewards_history.append(rewards.mean().item())
        
        # è·å–é«˜åº¦å’Œé€Ÿåº¦
        heights = env.root_states[:, 2].mean().item()
        velocities = env.root_states[:, 7:10].norm(dim=1).mean().item()
        heights_history.append(heights)
        velocities_history.append(velocities)
        
        # å®šæœŸæ‰“å°
        if (step + 1) % 100 == 0:
            print(f"Step {step+1}/{num_steps}:")
            print(f"  Mean reward: {rewards.mean():.4f}")
            print(f"  Mean height: {heights:.3f} m")
            print(f"  Mean velocity: {velocities:.3f} m/s")
            print(f"  Dones: {dones.sum().item()}/{env.num_envs}")
    
    print("\n" + "="*70)
    print("ğŸ“Š ä»¿çœŸç»Ÿè®¡:")
    print("="*70)
    
    # è®¡ç®—ç»Ÿè®¡
    rewards_np = np.array(rewards_history)
    heights_np = np.array(heights_history)
    velocities_np = np.array(velocities_history)
    
    print(f"Rewards:")
    print(f"  Mean: {rewards_np.mean():.4f}")
    print(f"  Std:  {rewards_np.std():.4f}")
    print(f"  Min:  {rewards_np.min():.4f}")
    print(f"  Max:  {rewards_np.max():.4f}")
    
    print(f"\nHeights (m):")
    print(f"  Mean: {heights_np.mean():.3f}")
    print(f"  Std:  {heights_np.std():.3f}")
    print(f"  Min:  {heights_np.min():.3f}")
    print(f"  Max:  {heights_np.max():.3f}")
    
    print(f"\nVelocities (m/s):")
    print(f"  Mean: {velocities_np.mean():.3f}")
    print(f"  Std:  {velocities_np.std():.3f}")
    print(f"  Min:  {velocities_np.min():.3f}")
    print(f"  Max:  {velocities_np.max():.3f}")
    
    print("\nâœ… ä»¿çœŸå®Œæˆï¼")
    
    # ä¿å­˜æ•°æ®ï¼ˆå¯é€‰ï¼‰
    save_data = False
    if save_data:
        import matplotlib.pyplot as plt
        
        fig, axes = plt.subplots(3, 1, figsize=(10, 8))
        
        axes[0].plot(rewards_history)
        axes[0].set_ylabel('Reward')
        axes[0].set_title('Reward History')
        axes[0].grid(True)
        
        axes[1].plot(heights_history)
        axes[1].set_ylabel('Height (m)')
        axes[1].set_title('Body Height')
        axes[1].grid(True)
        axes[1].axhline(y=0.5, color='r', linestyle='--', label='Target')
        axes[1].legend()
        
        axes[2].plot(velocities_history)
        axes[2].set_ylabel('Velocity (m/s)')
        axes[2].set_xlabel('Step')
        axes[2].set_title('Body Velocity')
        axes[2].grid(True)
        
        plt.tight_layout()
        plt.savefig('/home/abc/walk_these_ways_learning/hybrid_hopper_play.png')
        print(f"\nğŸ“Š ç»Ÿè®¡å›¾å·²ä¿å­˜: hybrid_hopper_play.png")

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--headless', action='store_true', help='Run in headless mode')
    parser.add_argument('--steps', type=int, default=1000, help='Number of steps to run')
    args = parser.parse_args()
    
    play_hybrid_hopper(headless=args.headless, num_steps=args.steps)
